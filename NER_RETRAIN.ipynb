{"cells":[{"cell_type":"code","source":["!pip install evaluate seqeval wikipedia\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oith73uOnke5","outputId":"32a16c1e-96b3-40d4-bbab-330392d784f3","executionInfo":{"status":"ok","timestamp":1763634066657,"user_tz":-330,"elapsed":10602,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.12/dist-packages (1.2.2)\n","Requirement already satisfied: wikipedia in /usr/local/lib/python3.12/dist-packages (1.4.0)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.4.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n","Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mqy99drDwLWB","executionInfo":{"status":"ok","timestamp":1763702808587,"user_tz":-330,"elapsed":44907,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"3f4345f9-b4a4-4444-d5f3-3946ff79b00d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OCgJRIr_nYNa","outputId":"cd76401b-5279-4044-db01-a2ad06d05f97","executionInfo":{"status":"ok","timestamp":1763634094906,"user_tz":-330,"elapsed":26653,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","‚úÖ All imports loaded successfully!\n","üìÅ ROOT directory: /content/drive/MyDrive/NER_RETRAIN\n","üéØ Environment ready for multilingual NER training!\n","\n","üöÄ GPU detected: Tesla T4\n","Using device: cuda\n"]}],"source":["# ======================================================\n","# SECTION 1 ‚Äî IMPORTS & SETUP (CORRECT COLAB VERSION)\n","# ======================================================\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import ast\n","import json\n","import random\n","import re\n","from pathlib import Path\n","from collections import defaultdict\n","import warnings\n","\n","warnings.filterwarnings('ignore')\n","\n","# ============================================\n","# COLAB: MOUNT GOOGLE DRIVE\n","# ============================================\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# ============================================\n","# Core ML libraries\n","# ============================================\n","from datasets import Dataset, DatasetDict, concatenate_datasets\n","from transformers import (\n","    XLMRobertaTokenizerFast,\n","    XLMRobertaForTokenClassification,\n","    TrainingArguments,\n","    Trainer,\n","    DataCollatorForTokenClassification\n",")\n","import evaluate\n","import nltk\n","import wikipedia\n","\n","# ============================================\n","# NLTK downloads\n","# ============================================\n","nltk.download('punkt', quiet=True)\n","nltk.download('stopwords', quiet=True)\n","\n","# ============================================\n","# Reproducibility\n","# ============================================\n","random.seed(42)\n","np.random.seed(42)\n","\n","# ============================================\n","# Set ROOT directory (YOUR DATA IS HERE)\n","# ============================================\n","ROOT = Path(\"/content/drive/MyDrive/NER_RETRAIN\")\n","ROOT.mkdir(parents=True, exist_ok=True)\n","\n","print(\"‚úÖ All imports loaded successfully!\")\n","print(f\"üìÅ ROOT directory: {ROOT}\")\n","print(\"üéØ Environment ready for multilingual NER training!\")\n","\n","# ============================================\n","# DEVICE CHECK\n","# ============================================\n","import torch\n","\n","if torch.cuda.is_available():\n","    DEVICE = torch.device(\"cuda\")\n","    print(\"\\nüöÄ GPU detected:\", torch.cuda.get_device_name(0))\n","else:\n","    DEVICE = torch.device(\"cpu\")\n","    print(\"\\n‚ö† Running on CPU (slower but fine for testing)\")\n","\n","print(\"Using device:\", DEVICE)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"evLM9UKSjUI_","colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"status":"ok","timestamp":1763634096081,"user_tz":-330,"elapsed":1172,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"b6fc034f-c240-4c42-9ef0-5ea30b30bf11"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìä Loading base datasets...\n","‚úÖ Loaded Hindi NER: 47959 examples\n","üìã Hindi columns: ['Sentence #', 'Sentence', 'POS', 'Tag']\n","‚úÖ Loaded India locations: 719 rows\n","üìã India columns: ['State Code', 'State Name', 'District Code', 'District Name']\n","\n","üìã Hindi NER Sample:\n"]},{"output_type":"execute_result","data":{"text/plain":["    Sentence #                                           Sentence  \\\n","0  Sentence: 1  Thousands of demonstrators have marched throug...   \n","1  Sentence: 2  Families of soldiers killed in the conflict jo...   \n","2  Sentence: 3  They marched from the Houses of Parliament to ...   \n","\n","                                                 POS  \\\n","0  ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...   \n","1  ['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...   \n","2  ['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...   \n","\n","                                                 Tag  \n","0  ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...  \n","1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n","2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  "],"text/html":["\n","  <div id=\"df-8def4c59-4609-4141-84cb-0d1a452121ab\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Sentence</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...</td>\n","      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 2</td>\n","      <td>Families of soldiers killed in the conflict jo...</td>\n","      <td>['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...</td>\n","      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 3</td>\n","      <td>They marched from the Houses of Parliament to ...</td>\n","      <td>['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...</td>\n","      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8def4c59-4609-4141-84cb-0d1a452121ab')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8def4c59-4609-4141-84cb-0d1a452121ab button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8def4c59-4609-4141-84cb-0d1a452121ab');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-26ad34cb-c4f7-4b96-910e-ee0801dcce32\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26ad34cb-c4f7-4b96-910e-ee0801dcce32')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-26ad34cb-c4f7-4b96-910e-ee0801dcce32 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"hindi_df","summary":"{\n  \"name\": \"hindi_df\",\n  \"rows\": 47959,\n  \"fields\": [\n    {\n      \"column\": \"Sentence #\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47959,\n        \"samples\": [\n          \"Sentence: 13390\",\n          \"Sentence: 3036\",\n          \"Sentence: 6014\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47575,\n        \"samples\": [\n          \"India 's government has warned the national media not to publish anything that hurts the feelings of any religious community .\",\n          \"Meanwhile , the U.N. secretary-general 's special representative for children and armed conflict concluded a five-day visit to Iraq Friday .\",\n          \"A government health official says illnesses caused by contaminated water have killed at least 66 people , and there are fears the TRUE death toll could be far higher , since many cases have not been reported .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47214,\n        \"samples\": [\n          \"['NNP', 'VBZ', 'VBN', 'IN', 'DT', 'JJ', 'NNS', 'IN', 'DT', 'NNS', 'CC', 'VBZ', 'RB', 'VBN', 'IN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\",\n          \"['DT', 'NN', 'IN', 'NNS', 'IN', 'JJ', 'NNS', 'VBZ', 'VBN', 'TO', 'VB', 'IN', 'DT', 'NN', 'IN', 'NN', 'VBG', 'DT', 'NN', 'IN', 'NNP', 'NNP', '.']\",\n          \"['RB', 'CD', 'NN', 'VBD', 'PRP', 'VBD', 'IN', 'DT', 'NN', 'NNP', 'VBZ', 'PRP$', 'NN', '.']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tag\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33318,\n        \"samples\": [\n          \"['B-geo', 'O', 'B-geo', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\",\n          \"['B-gpe', 'O', 'B-per', 'I-per', 'I-per', 'O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\",\n          \"['B-per', 'I-per', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":4}],"source":["# ======================================================\n","# SECTION 2 ‚Äî LOAD BASE DATASETS\n","# ======================================================\n","\n","print(\"üìä Loading base datasets...\")\n","\n","# Set dataset paths inside Google Drive\n","HINDI_NER_PATH = \"/content/drive/MyDrive/NER_RETRAIN/ner.csv\"\n","INDIA_LOC_PATH = \"/content/drive/MyDrive/NER_RETRAIN/India District (1).xlsx\"\n","\n","# Load Hindi NER dataset\n","hindi_df = pd.read_csv(HINDI_NER_PATH)\n","print(f\"‚úÖ Loaded Hindi NER: {len(hindi_df)} examples\")\n","print(f\"üìã Hindi columns: {list(hindi_df.columns)}\")\n","\n","# Load India locations dataset\n","india_df = pd.read_excel(INDIA_LOC_PATH)\n","print(f\"‚úÖ Loaded India locations: {len(india_df)} rows\")\n","print(f\"üìã India columns: {list(india_df.columns)}\")\n","\n","# Display sample data\n","print(\"\\nüìã Hindi NER Sample:\")\n","hindi_df.head(3)\n"]},{"cell_type":"code","source":["# ======================================================\n","# SECTION 3 ‚Äî PREPROCESS HINDI NER DATA\n","# ======================================================\n","\n","import ast\n","\n","print(\"üîß Preprocessing Hindi NER dataset...\")\n","\n","# Convert string list columns ‚Üí Python lists\n","def safe_parse_list(x):\n","    try:\n","        return ast.literal_eval(x)\n","    except:\n","        return []\n","\n","hindi_df[\"POS\"] = hindi_df[\"POS\"].apply(safe_parse_list)\n","hindi_df[\"Tag\"] = hindi_df[\"Tag\"].apply(safe_parse_list)\n","\n","# Basic cleaning of sentence\n","hindi_df[\"Sentence\"] = hindi_df[\"Sentence\"].apply(\n","    lambda x: x.replace(\"Sentence: \", \"\").strip()\n",")\n","\n","print(\"üîç Sample after conversion:\")\n","print(hindi_df.head(2))\n","\n","# Check token alignment\n","bad_rows = hindi_df[\n","    hindi_df.apply(lambda row: len(row[\"POS\"]) != len(row[\"Tag\"]), axis=1)\n","]\n","\n","print(f\"\\n‚ö† Misaligned rows: {len(bad_rows)}\")\n","print(\"If > 0, we will fix in next step.\")\n"],"metadata":{"id":"jMit0lXjo_kA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763634107689,"user_tz":-330,"elapsed":11605,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"78bdb672-805b-4367-f5a2-42d7441b3eeb"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Preprocessing Hindi NER dataset...\n","üîç Sample after conversion:\n","    Sentence #                                           Sentence  \\\n","0  Sentence: 1  Thousands of demonstrators have marched throug...   \n","1  Sentence: 2  Families of soldiers killed in the conflict jo...   \n","\n","                                                 POS  \\\n","0  [NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...   \n","1  [NNS, IN, NNS, VBN, IN, DT, NN, VBD, DT, NNS, ...   \n","\n","                                                 Tag  \n","0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...  \n","1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n","\n","‚ö† Misaligned rows: 0\n","If > 0, we will fix in next step.\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"1FUXdxsJjYvv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763634108083,"user_tz":-330,"elapsed":389,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"229f4191-f78c-4066-ebde-7a8e2afdc9a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üì• Loading CoNLL datasets...\n","‚úÖ CoNLL Train: 14987 sentences\n","‚úÖ CoNLL Valid: 3466 sentences\n","‚úÖ CoNLL Test: 3684 sentences\n","\n","üìã Sample CoNLL sentence:\n","['Port', 'conditions', 'from', 'Lloyds', 'Shipping', 'Intelligence', 'Service', '--']\n","['O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O']\n"]}],"source":["# ======================================================\n","# SECTION 4 ‚Äî LOAD CoNLL ENGLISH DATASETS (FIXED FOR COLAB)\n","# ======================================================\n","\n","print(\"\\nüì• Loading CoNLL datasets...\")\n","\n","def load_conll_file(path):\n","    sentences, ner_tags = [], []\n","    tokens, tags = [], []\n","\n","    with open(path, \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            line = line.strip()\n","\n","            if not line:\n","                # Sentence boundary\n","                if tokens:\n","                    sentences.append(tokens)\n","                    ner_tags.append(tags)\n","                    tokens, tags = [], []\n","                continue\n","\n","            parts = line.split()\n","            tokens.append(parts[0])\n","            tags.append(parts[-1])\n","\n","    return sentences, ner_tags\n","\n","# CORRECT PATH FOR COLAB\n","conll_path = \"/content/drive/MyDrive/NER_RETRAIN/conll2003\"\n","\n","train_sentences, train_tags = load_conll_file(f\"/content/drive/MyDrive/NER_RETRAIN/eng.train\")\n","valid_sentences, valid_tags = load_conll_file(f\"/content/drive/MyDrive/NER_RETRAIN/eng.testa\")\n","test_sentences, test_tags = load_conll_file(f\"/content/drive/MyDrive/NER_RETRAIN/eng.testb\")\n","\n","print(f\"‚úÖ CoNLL Train: {len(train_sentences)} sentences\")\n","print(f\"‚úÖ CoNLL Valid: {len(valid_sentences)} sentences\")\n","print(f\"‚úÖ CoNLL Test: {len(test_sentences)} sentences\")\n","\n","# Show a sample\n","print(\"\\nüìã Sample CoNLL sentence:\")\n","print(train_sentences[100])\n","print(train_tags[100])\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"3Gj-hEWijcMX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763634108106,"user_tz":-330,"elapsed":20,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"8b68c90a-f641-46c5-e2eb-28e56d5950d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["üì• Loading extended synthetic dataset...\n","‚úÖ Loaded comprehensive dataset: 3992 examples\n","üìç States: 36\n","üìç Districts: 712\n","üéØ Total unique Indian locations: 748\n","‚úÖ Tag normalization function ready!\n"]}],"source":["# ======================================================\n","# SECTION 5 ‚Äî LOAD SYNTHETIC + COMPREHENSIVE DATASET\n","# ======================================================\n","\n","print(\"üì• Loading extended synthetic dataset...\")\n","\n","COMPREHENSIVE_PATH = \"/content/drive/MyDrive/NER_RETRAIN/comprehensive_indian_ner_dataset.csv\"\n","\n","# Try loading comprehensive dataset\n","try:\n","    comprehensive_df = pd.read_csv(COMPREHENSIVE_PATH)\n","    print(f\"‚úÖ Loaded comprehensive dataset: {len(comprehensive_df)} examples\")\n","\n","except Exception as e:\n","    comprehensive_df = None\n","    print(f\"‚ö†Ô∏è Could not load comprehensive dataset: {e}\")\n","\n","# Extract all states and districts anyway\n","indian_states = set(india_df[\"State Name\"].dropna().unique())\n","indian_districts = set(india_df[\"District Name\"].dropna().unique())\n","all_indian_locations = list(indian_states.union(indian_districts))\n","\n","print(f\"üìç States: {len(indian_states)}\")\n","print(f\"üìç Districts: {len(indian_districts)}\")\n","print(f\"üéØ Total unique Indian locations: {len(all_indian_locations)}\")\n","\n","# Clean/normalize tags (B-LOC / I-LOC / O)\n","def normalize_tag(tag):\n","    tag = str(tag).upper() if not pd.isna(tag) else \"O\"\n","\n","    if any(k in tag for k in [\"LOC\", \"GEO\", \"GPE\"]):\n","        if tag.startswith(\"B-\") or tag.startswith(\"B_\"):\n","            return \"B-LOC\"\n","        elif tag.startswith(\"I-\") or tag.startswith(\"I_\"):\n","            return \"I-LOC\"\n","    return \"O\"\n","\n","print(\"‚úÖ Tag normalization function ready!\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"rIoSUwiEjh6N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763634120606,"user_tz":-330,"elapsed":12498,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"51d13743-2304-422c-a944-e2458c41c7ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîÑ Processing Hindi NER dataset...\n","‚úÖ Processed 47955 Hindi sentences\n","üîÑ Processing CoNLL datasets...\n","‚úÖ Processed 22137 CoNLL sentences\n","\n","üìä Tag distribution in processed data:\n","O        1277795\n","B-LOC      64158\n","I-LOC       9283\n","Name: count, dtype: int64\n","üìà Location coverage: 5.4%\n"]}],"source":["# Process Hindi dataset\n","print(\"üîÑ Processing Hindi NER dataset...\")\n","\n","hindi_sentences = []\n","hindi_tags_normalized = []\n","\n","for idx, row in hindi_df.iterrows():\n","    try:\n","        # Parse sentence and tags\n","        tokens = row['Sentence'].split()\n","        tags = ast.literal_eval(row['Tag']) if isinstance(row['Tag'], str) else row['Tag']\n","\n","        # Ensure equal length\n","        if len(tokens) == len(tags):\n","            # Normalize tags\n","            normalized_tags = [normalize_tag(tag) for tag in tags]\n","            hindi_sentences.append(tokens)\n","            hindi_tags_normalized.append(normalized_tags)\n","    except Exception as e:\n","        continue  # Skip problematic rows\n","\n","print(f\"‚úÖ Processed {len(hindi_sentences)} Hindi sentences\")\n","\n","# Process CoNLL datasets\n","print(\"üîÑ Processing CoNLL datasets...\")\n","\n","conll_sentences = train_sentences + valid_sentences + test_sentences\n","conll_tags_raw = train_tags + valid_tags + test_tags\n","\n","conll_tags_normalized = []\n","for tag_sequence in conll_tags_raw:\n","    normalized_tags = [normalize_tag(tag) for tag in tag_sequence]\n","    conll_tags_normalized.append(normalized_tags)\n","\n","print(f\"‚úÖ Processed {len(conll_sentences)} CoNLL sentences\")\n","\n","# Show tag distribution\n","all_tags_flat = []\n","for seq in hindi_tags_normalized + conll_tags_normalized:\n","    all_tags_flat.extend(seq)\n","\n","tag_counts = pd.Series(all_tags_flat).value_counts()\n","print(f\"\\nüìä Tag distribution in processed data:\")\n","print(tag_counts)\n","print(f\"üìà Location coverage: {(tag_counts['B-LOC'] + tag_counts['I-LOC']) / len(all_tags_flat) * 100:.1f}%\")"]},{"cell_type":"code","source":["# ======================================================\n","# ADVANCED SYNTHETIC DATA GENERATION + DATASET PREP\n","# (Run this in your Colab after the preprocessing cells)\n","# ======================================================\n","\n","import random\n","from pathlib import Path\n","import pandas as pd\n","from datasets import Dataset, DatasetDict\n","from transformers import XLMRobertaTokenizerFast\n","import json\n","\n","ROOT = Path(\"/content/drive/MyDrive/NER_RETRAIN\")\n","ROOT.mkdir(parents=True, exist_ok=True)\n","\n","print(\"üöÄ Starting ADVANCED synthetic generation and dataset prep...\")\n","\n","# --- 1) Build list of unique states & districts from india_df ---\n","india_df_clean = india_df.copy()\n","india_df_clean[\"State Name\"] = india_df_clean[\"State Name\"].astype(str).str.strip()\n","india_df_clean[\"District Name\"] = india_df_clean[\"District Name\"].astype(str).str.strip()\n","\n","# create pairs (district, state)\n","pairs = india_df_clean[[\"District Name\", \"State Name\"]].dropna().drop_duplicates().values.tolist()\n","print(f\"üìç Unique district-state pairs: {len(pairs)}\")\n","\n","# --- 2) Templates (5 variations) ---\n","templates = [\n","    \"{district} is located in {state}.\",\n","    \"People living in {district} district of {state} often say ...\",\n","    \"{state} includes {district} as one of its districts.\",\n","    \"{district}, {state}, is known for its culture and history.\",\n","    \"Travelers often visit {district} in {state} during holidays.\"\n","]\n","\n","# --- 3) Generate synthetic sentences (5 variations per pair) ---\n","synthetic_sentences = []\n","synthetic_tags = []\n","\n","for district, state in pairs:\n","    district = str(district).strip()\n","    state = str(state).strip()\n","    for t in templates:\n","        sent = t.format(district=district, state=state)\n","        tokens = sent.split()\n","        tags = []\n","        # create tagging: mark whole district as B-LOC I-LOC... and state as B-LOC I-LOC...\n","        # We detect token-by-token equality to district/state (exact token match)\n","        # For multi-token names (e.g., \"North Andaman\"), we detect contiguous token spans.\n","        # Simple approach: find span of district tokens and state tokens in sentence tokens\n","        def find_span(name_tokens, tokens):\n","            n = len(name_tokens)\n","            for i in range(len(tokens) - n + 1):\n","                if tokens[i:i+n] == name_tokens:\n","                    return i, i+n  # start inclusive, end exclusive\n","            return None\n","\n","        toks = tokens\n","        district_tokens = district.split()\n","        state_tokens = state.split()\n","\n","        # default O\n","        tags = [\"O\"] * len(toks)\n","\n","        # mark district\n","        span = find_span(district_tokens, toks)\n","        if span:\n","            s, e = span\n","            tags[s] = \"B-LOC\"\n","            for idx in range(s+1, e):\n","                tags[idx] = \"I-LOC\"\n","\n","        # mark state (don't overwrite if overlapping‚Äîwe keep district marking precedence)\n","        span2 = find_span(state_tokens, toks)\n","        if span2:\n","            s, e = span2\n","            # only write if those positions are still O\n","            if tags[s] == \"O\":\n","                tags[s] = \"B-LOC\"\n","            else:\n","                # if already B-LOC (rare overlap), keep it\n","                tags[s] = tags[s]\n","            for idx in range(s+1, e):\n","                if tags[idx] == \"O\":\n","                    tags[idx] = \"I-LOC\"\n","\n","        synthetic_sentences.append(toks)\n","        synthetic_tags.append(tags)\n","\n","print(f\"‚úÖ Synthetic sentences generated: {len(synthetic_sentences)} (expected {len(pairs)*len(templates)})\")\n","\n","# --- 4) Merge data\n","# Note: expects variables from your previous preprocessing:\n","# - hindi_sentences: list[list[str]]\n","# - hindi_tags_normalized: list[list[str]]\n","# - train_sentences, valid_sentences, test_sentences: lists of token lists\n","# - train_tags, valid_tags, test_tags: lists of tag lists (normalized)\n","# The cell earlier produced conll_tags_normalized; if you have different names adjust them.\n","\n","# If conll tags variables are named differently use this fallback:\n","try:\n","    conll_train_tags = train_tags\n","    conll_valid_tags = valid_tags\n","    conll_test_tags = test_tags\n","except NameError:\n","    # if raw conll tags were normalized into conll_tags_normalized and combined, split:\n","    try:\n","        raise\n","    except:\n","        pass\n","\n","# Build training pool:\n","train_tokens = hindi_sentences + train_sentences + synthetic_sentences\n","train_labels = hindi_tags_normalized + train_tags + synthetic_tags\n","\n","# Validation and test from CoNLL (keep original splits)\n","valid_tokens = valid_sentences\n","valid_labels = valid_tags\n","test_tokens = test_sentences\n","test_labels = test_tags\n","\n","print(f\"üìö Train sentences: {len(train_tokens)}\")\n","print(f\"üìö Valid sentences: {len(valid_tokens)}\")\n","print(f\"üìö Test sentences: {len(test_tokens)}\")\n","\n","# --- 5) Build tag set and mappings (ensure consistent ordering) ---\n","unique_tags = sorted({t for seq in (train_labels + valid_labels + test_labels) for t in seq})\n","tag2id = {t: i for i, t in enumerate(unique_tags)}\n","id2tag = {i: t for t, i in tag2id.items()}\n","\n","print(\"üîñ Tags:\", unique_tags)\n","print(\"üî¢ tag2id:\", tag2id)\n","\n","# --- 6) Tokenizer & alignment for XLM-R ---\n","tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n","\n","def tokenize_and_align_labels(examples_tokens, examples_labels):\n","    tokenized_inputs = tokenizer(\n","        examples_tokens,\n","        is_split_into_words=True,\n","        truncation=True,\n","        padding=False  # no padding here; HF Trainer will handle batching\n","    )\n","    all_labels = []\n","    for i, labels in enumerate(examples_labels):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:\n","            if word_idx is None:\n","                # Special token\n","                label_ids.append(-100)\n","            elif word_idx != previous_word_idx:\n","                # Start of a new word\n","                label_ids.append(tag2id.get(labels[word_idx], tag2id.get(\"O\")))\n","            else:\n","                # Same word, set to I-... if original tag was B-LOC, change to I-LOC for subword token\n","                orig_tag = labels[word_idx]\n","                if orig_tag == \"B-LOC\":\n","                    label_ids.append(tag2id.get(\"I-LOC\", tag2id.get(\"O\")))\n","                else:\n","                    label_ids.append(tag2id.get(orig_tag, tag2id.get(\"O\")))\n","            previous_word_idx = word_idx\n","        all_labels.append(label_ids)\n","    tokenized_inputs[\"labels\"] = all_labels\n","    return tokenized_inputs\n","\n","# --- 7) Create HF Datasets (tokenize on-the-fly) ---\n","print(\"‚ú≥ Tokenizing & aligning labels for train (this may take a bit)...\")\n","train_tokenized = tokenize_and_align_labels(train_tokens, train_labels)\n","print(\"‚ú≥ Tokenizing & aligning labels for valid...\")\n","valid_tokenized = tokenize_and_align_labels(valid_tokens, valid_labels)\n","print(\"‚ú≥ Tokenizing & aligning labels for test...\")\n","test_tokenized = tokenize_and_align_labels(test_tokens, test_labels)\n","\n","# Convert to datasets.Dataset\n","train_ds = Dataset.from_dict(train_tokenized)\n","valid_ds = Dataset.from_dict(valid_tokenized)\n","test_ds = Dataset.from_dict(test_tokenized)\n","\n","dataset_dict = DatasetDict({\"train\": train_ds, \"validation\": valid_ds, \"test\": test_ds})\n","\n","# --- 8) Save small samples and mappings ---\n","sample_csv = ROOT / \"synthetic_sample_head.csv\"\n","pd.DataFrame({\n","    \"tokens\": [\" \".join(t) for t in train_tokens[:8]],\n","    \"labels\": [\" \".join(l) for l in train_labels[:8]]\n","}).to_csv(sample_csv, index=False)\n","\n","with open(ROOT / \"tag2id.json\", \"w\") as f:\n","    json.dump(tag2id, f, ensure_ascii=False, indent=2)\n","with open(ROOT / \"id2tag.json\", \"w\") as f:\n","    json.dump(id2tag, f, ensure_ascii=False, indent=2)\n","\n","print(\"üíæ Saved sample and tag maps to Drive:\", ROOT)\n","\n","# --- 9) Print quick stats & sample ---\n","print(\"\\n=== Final Dataset Sizes ===\")\n","print(\"Train:\", len(dataset_dict[\"train\"]))\n","print(\"Validation:\", len(dataset_dict[\"validation\"]))\n","print(\"Test:\", len(dataset_dict[\"test\"]))\n","\n","print(\"\\n=== Example (tokenized) ===\")\n","for i in range(2):\n","    ex = dataset_dict[\"train\"][i]\n","    words = tokenizer.convert_ids_to_tokens(ex[\"input_ids\"])\n","    print(\"\\nTokens:\", words)\n","    print(\"Labels:\", ex[\"labels\"])\n","\n","print(\"\\n‚úÖ ADVANCED synthetic generation + tokenization completed.\")\n","print(\"Next: define TrainingArguments & Trainer (I can prepare that cell for you).\")\n"],"metadata":{"id":"3kXYt3w3rnv0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763634146727,"user_tz":-330,"elapsed":26110,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"c0ac2549-3e50-4c54-b1fb-c150f8cd6436"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ Starting ADVANCED synthetic generation and dataset prep...\n","üìç Unique district-state pairs: 719\n","‚úÖ Synthetic sentences generated: 3595 (expected 3595)\n","üìö Train sentences: 66537\n","üìö Valid sentences: 3466\n","üìö Test sentences: 3684\n","üîñ Tags: ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n","üî¢ tag2id: {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 4, 'I-MISC': 5, 'I-ORG': 6, 'I-PER': 7, 'O': 8}\n","‚ú≥ Tokenizing & aligning labels for train (this may take a bit)...\n","‚ú≥ Tokenizing & aligning labels for valid...\n","‚ú≥ Tokenizing & aligning labels for test...\n","üíæ Saved sample and tag maps to Drive: /content/drive/MyDrive/NER_RETRAIN\n","\n","=== Final Dataset Sizes ===\n","Train: 66537\n","Validation: 3466\n","Test: 3684\n","\n","=== Example (tokenized) ===\n","\n","Tokens: ['<s>', '‚ñÅTho', 'usan', 'ds', '‚ñÅof', '‚ñÅdemonstra', 'tors', '‚ñÅhave', '‚ñÅmarche', 'd', '‚ñÅthrough', '‚ñÅLondon', '‚ñÅto', '‚ñÅprotest', '‚ñÅthe', '‚ñÅwar', '‚ñÅin', '‚ñÅIraq', '‚ñÅand', '‚ñÅdemand', '‚ñÅthe', '‚ñÅwithdraw', 'al', '‚ñÅof', '‚ñÅBritish', '‚ñÅtro', 'ops', '‚ñÅfrom', '‚ñÅthat', '‚ñÅcountry', '‚ñÅ', '.', '</s>']\n","Labels: [-100, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, -100]\n","\n","Tokens: ['<s>', '‚ñÅFamilie', 's', '‚ñÅof', '‚ñÅsoldi', 'ers', '‚ñÅkilled', '‚ñÅin', '‚ñÅthe', '‚ñÅconflict', '‚ñÅjoin', 'ed', '‚ñÅthe', '‚ñÅprotest', 'ers', '‚ñÅwho', '‚ñÅcarried', '‚ñÅbanner', 's', '‚ñÅwith', '‚ñÅsuch', '‚ñÅslogan', 's', '‚ñÅas', '‚ñÅ\"', '‚ñÅBush', '‚ñÅNumber', '‚ñÅOne', '‚ñÅTerror', 'ist', '‚ñÅ\"', '‚ñÅand', '‚ñÅ\"', '‚ñÅStop', '‚ñÅthe', '‚ñÅBomb', 'ings', '‚ñÅ', '.', '‚ñÅ\"', '</s>']\n","Labels: [-100, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, -100]\n","\n","‚úÖ ADVANCED synthetic generation + tokenization completed.\n","Next: define TrainingArguments & Trainer (I can prepare that cell for you).\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"MdBXZS8nmZ3b","executionInfo":{"status":"ok","timestamp":1763634146735,"user_tz":-330,"elapsed":6,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}}},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"uJ9hBfgDx440","executionInfo":{"status":"ok","timestamp":1763634146748,"user_tz":-330,"elapsed":11,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["!pip install -U transformers datasets evaluate accelerate seqeval\n","\n","# ======================================================\n","# FINAL TRAINING BLOCK ‚Äî MULTILINGUAL XLM-R NER MODEL\n","# ======================================================\n","\n","from transformers import (\n","    XLMRobertaForTokenClassification,\n","    TrainingArguments,\n","    Trainer,\n","    DataCollatorForTokenClassification\n",")\n","import evaluate\n","import numpy as np\n","import torch\n","\n","SAVE_DIR = \"/content/drive/MyDrive/NER_RETRAIN/xlmr_location_ner\"\n","\n","print(\"üìÅ Final model will be saved to:\", SAVE_DIR)\n","\n","# ------------------------------------------------------\n","# Auto-select batch size depending on GPU/CPU\n","# ------------------------------------------------------\n","if torch.cuda.is_available():\n","    BATCH_SIZE = 16\n","    FP16 = True\n","    print(\"üöÄ GPU detected ‚Äî Using batch size =\", BATCH_SIZE)\n","else:\n","    BATCH_SIZE = 2\n","    FP16 = False\n","    print(\"‚ö†Ô∏è CPU detected ‚Äî Using batch size =\", BATCH_SIZE)\n","\n","# ------------------------------------------------------\n","# Load model backbone\n","# ------------------------------------------------------\n","model = XLMRobertaForTokenClassification.from_pretrained(\n","    \"xlm-roberta-base\",\n","    num_labels=len(tag2id),\n","    id2label=id2tag,\n","    label2id=tag2id\n",")\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer)\n","\n","# ------------------------------------------------------\n","# Define eval metric (seqeval)\n","# ------------------------------------------------------\n","seqeval = evaluate.load(\"seqeval\")\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    preds = np.argmax(logits, axis=-1)\n","\n","    true_preds = []\n","    true_labels = []\n","\n","    for pred, lab in zip(preds, labels):\n","        for p, l in zip(pred, lab):\n","            if l != -100:  # ignore special tokens\n","                true_preds.append(id2tag[p])\n","                true_labels.append(id2tag[l])\n","\n","    # seqeval expects list of lists, so wrap in one sequence\n","    true_preds = [true_preds]\n","    true_labels = [true_labels]\n","\n","    results = seqeval.compute(predictions=true_preds, references=true_labels)\n","    return {\n","        \"precision\": results[\"overall_precision\"],\n","        \"recall\": results[\"overall_recall\"],\n","        \"f1\": results[\"overall_f1\"],\n","        \"accuracy\": results[\"overall_accuracy\"]\n","    }\n","\n","# ------------------------------------------------------\n","# TrainingArguments\n","# ------------------------------------------------------\n","training_args = TrainingArguments(\n","    output_dir=SAVE_DIR,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    logging_steps=200,\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    weight_decay=0.01,\n","    num_train_epochs=2,\n","    fp16=FP16,\n","    load_best_model_at_end=True,\n","    push_to_hub=False\n",")\n","\n","# ------------------------------------------------------\n","# Trainer\n","# ------------------------------------------------------\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset_dict[\"train\"],\n","    eval_dataset=dataset_dict[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# ------------------------------------------------------\n","# START TRAINING\n","# ------------------------------------------------------\n","print(\"\\nüöÄ Starting training...\\n\")\n","trainer.train()\n","\n","# ------------------------------------------------------\n","# SAVE FINAL MODEL\n","# ------------------------------------------------------\n","trainer.save_model(SAVE_DIR)\n","tokenizer.save_pretrained(SAVE_DIR)\n","\n","print(\"\\nüéâ Training complete!\")\n","print(\"üíæ Final model saved at:\", SAVE_DIR)\n"],"metadata":{"id":"_ojUBUp0tJNq","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1763638808301,"user_tz":-330,"elapsed":253628,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"a38a55a2-0e55-496b-84d3-0d79ce647af4"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.12/dist-packages (1.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n","Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n","üìÅ Final model will be saved to: /content/drive/MyDrive/NER_RETRAIN/xlmr_location_ner\n","üöÄ GPU detected ‚Äî Using batch size = 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]},{"output_type":"stream","name":"stdout","text":["\n","üöÄ Starting training...\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1833' max='8318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1833/8318 03:58 < 14:03, 7.69 it/s, Epoch 0.44/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-368381651.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m# ------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüöÄ Starting training...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# ------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2672\u001b[0m                     )\n\u001b[1;32m   2673\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4019\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4020\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4022\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4108\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4109\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4110\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4111\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4112\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1388\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    854\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0mlayer_head_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhead_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    608\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mcache_position\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     ) -> tuple[torch.Tensor]:\n\u001b[0;32m--> 514\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mcache_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         )\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"32de84c1","executionInfo":{"status":"ok","timestamp":1763702712807,"user_tz":-330,"elapsed":6,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}}},"source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\""],"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os\n","from getpass import getpass\n","\n","# This will NOT echo the key when you paste it\n","os.environ[\"GROQ_API_KEY\"] = getpass(\"Paste your new GROQ API key: \")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkOy38pp87b6","executionInfo":{"status":"ok","timestamp":1763702740551,"user_tz":-330,"elapsed":26986,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"b032c25b-057a-496f-86d1-a883d2446bd4"},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":["Paste your new GROQ API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"]}]},{"cell_type":"code","source":["!pip install -q groq\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQhCygzI9N0M","executionInfo":{"status":"ok","timestamp":1763702760565,"user_tz":-330,"elapsed":18006,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"1d474002-2bf8-4902-d98a-698505529aea"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/137.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ\u001b[0m \u001b[32m133.1/137.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.3/137.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from groq import Groq\n","\n","client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n"],"metadata":{"id":"wICkICDi9QaP","executionInfo":{"status":"ok","timestamp":1763702763637,"user_tz":-330,"elapsed":3068,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import torch\n","import json\n","\n","MODEL_PATH = \"/content/drive/MyDrive/NER_RETRAIN/xlmr_location_ner\"\n","\n","tokenizer = XLMRobertaTokenizerFast.from_pretrained(MODEL_PATH)\n","model = XLMRobertaForTokenClassification.from_pretrained(MODEL_PATH)\n","model.eval()\n","model.to(DEVICE) # Move the model to the correct device\n","\n","with open(\"/content/drive/MyDrive/NER_RETRAIN/id2tag.json\") as f:\n","    id2tag = {int(k):v for k,v in json.load(f).items()}\n","\n","def extract_locations(text):\n","    toks = tokenizer(text, return_tensors=\"pt\")\n","    toks = {k: v.to(DEVICE) for k, v in toks.items()} # Move input tensors to the correct device\n","    with torch.no_grad():\n","        logits = model(**toks).logits[0]\n","\n","    preds = torch.argmax(logits, dim=-1).tolist()\n","    tokens = tokenizer.convert_ids_to_tokens(toks[\"input_ids\"][0])\n","\n","    locations = []\n","    buf = \"\"\n","\n","    for tok, p in zip(tokens, preds):\n","        label = id2tag[p]\n","        tok = tok.replace(\" \", \"\")\n","\n","        if label == \"B-LOC\":\n","            if buf:\n","                locations.append(buf)\n","            buf = tok\n","        elif label == \"I-LOC\":\n","            buf += \" \" + tok\n","        else:\n","            if buf:\n","                locations.append(buf)\n","                buf = \"\"\n","\n","    if buf:\n","        locations.append(buf)\n","\n","    return list(set(locations))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"_K62vq5Z9VDW","executionInfo":{"status":"error","timestamp":1763702885876,"user_tz":-330,"elapsed":54,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"335bf07b-29ae-434d-ce83-074c3fa55414"},"execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'XLMRobertaTokenizerFast' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2894826536.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMODEL_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/NER_RETRAIN/xlmr_location_ner\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXLMRobertaTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXLMRobertaForTokenClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'XLMRobertaTokenizerFast' is not defined"]}]},{"cell_type":"code","source":["def analyze_incident_with_llm(text, locations):\n","    prompt = f\"\"\"\n","You are an AI incident-analysis engine for Indian news.\n","\n","Given a news text and a list of detected locations, extract:\n","\n","1. classification: \"GOOD\", \"BAD\", or \"NEUTRAL\"\n","2. event_type: (accident, crime, political, natural disaster, achievement, other)\n","3. severity: low / medium / high\n","4. deaths: number of deaths if mentioned\n","5. injured: number injured\n","6. main_incident_location: which location is the event-site\n","7. other_locations: everything else\n","8. summary: one sentence summary\n","\n","TEXT: {text}\n","LOCATIONS: {locations}\n","\n","Return ONLY valid JSON.\n","\"\"\"\n","\n","    response = client.chat.completions.create(\n","        model=\"llama-3.1-8b-instant\", # Changed to a valid model\n","        messages=[{\"role\": \"user\", \"content\": prompt}],\n","        temperature=0.1\n","    )\n","\n","    return response.choices[0].message.content"],"metadata":{"id":"T375vLOh9Zx7","executionInfo":{"status":"ok","timestamp":1763638956680,"user_tz":-330,"elapsed":5,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["india_df = pd.read_excel(\"/content/drive/MyDrive/NER_RETRAIN/India District (1).xlsx\")\n","\n","def lookup_location_info(location):\n","    # Try district match\n","    row = india_df[india_df[\"District Name\"].str.lower() == location.lower()]\n","    if not row.empty:\n","        r = row.iloc[0]\n","        return {\n","            \"district\": r[\"District Name\"],\n","            \"state\": r[\"State Name\"],\n","            \"district_code\": int(r[\"District Code\"]),\n","            \"state_code\": int(r[\"State Code\"])\n","        }\n","\n","    # Try state match\n","    row = india_df[india_df[\"State Name\"].str.lower() == location.lower()]\n","    if not row.empty:\n","        r = row.iloc[0]\n","        return {\n","            \"district\": None,\n","            \"state\": r[\"State Name\"],\n","            \"district_code\": None,\n","            \"state_code\": int(r[\"State Code\"])\n","        }\n","\n","    return None\n"],"metadata":{"id":"eqYcH-DX9diM","executionInfo":{"status":"ok","timestamp":1763638960646,"user_tz":-330,"elapsed":443,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["import re\n","import json\n","\n","def extract_json(text):\n","    \"\"\"\n","    Extract the first valid JSON object from any LLM output.\n","    \"\"\"\n","\n","    # Find JSON block with regex\n","    match = re.search(r\"\\{[\\s\\S]*\\}\", text)\n","\n","    if match:\n","        json_str = match.group(0)\n","\n","        # Try to load JSON\n","        try:\n","            return json.loads(json_str)\n","        except:\n","            pass\n","\n","    # If still failing, try fixing common issues:\n","    text = text.strip()\n","\n","    # Remove markdown fences\n","    text = text.replace(\"```json\", \"\").replace(\"```\", \"\")\n","\n","    # Attempt direct load\n","    try:\n","        return json.loads(text)\n","    except:\n","        raise ValueError(\"‚ùå Could not parse JSON from LLM output:\\n\" + text)\n","\n","\n","def extract_full_incident(text):\n","    # Step 1: Location detection\n","    locations = extract_locations(text)\n","\n","    # Step 2: LLM incident analysis\n","    llm_json = analyze_incident_with_llm(text, locations)\n","\n","    # Step 3: Robust JSON extraction\n","    data = extract_json(llm_json)\n","\n","    # Step 4: Excel mapping for main incident location\n","    main_loc = data.get(\"main_incident_location\")\n","    if main_loc:\n","        data[\"location_details\"] = lookup_location_info(main_loc)\n","\n","    return data"],"metadata":{"id":"Pfd00prF9gu3","executionInfo":{"status":"ok","timestamp":1763638962483,"user_tz":-330,"elapsed":22,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["text = \"Chennai and Bangalore have a water war and 3 people died in Dindigul.\"\n","\n","result = extract_full_incident(text)\n","result\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2n9iLDck9kCF","executionInfo":{"status":"ok","timestamp":1763638965348,"user_tz":-330,"elapsed":649,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"bc1e02ce-95f2-4a7f-f116-2848d45cbb41"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'classification': 'BAD',\n"," 'event_type': 'accident',\n"," 'severity': 'high',\n"," 'deaths': 3,\n"," 'injured': None,\n"," 'main_incident_location': 'Dindigul',\n"," 'other_locations': ['Chennai', 'Bangalore'],\n"," 'summary': 'A water war between Chennai and Bangalore resulted in 3 deaths in Dindigul.',\n"," 'location_details': {'district': 'Dindigul',\n","  'state': 'TAMIL NADU',\n","  'district_code': 612,\n","  'state_code': 33}}"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["text = \"After weeks of tension between farmers in Erode and textile groups in Tiruppur over shared river access, a violent clash broke out on Thursday evening. While the dispute began near Kodumudi, the most serious incident occurred 40 km away in Karur district, where one protester succumbed to injuries sustained during stone-pelting. Police from Coimbatore were rushed to both locations, and the state government said the situation was now under control.\"\n","\n","result = extract_full_incident(text)\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2Uby4NDAQoH","executionInfo":{"status":"ok","timestamp":1763639113542,"user_tz":-330,"elapsed":466,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"9b814ba0-0fb7-478a-aa1d-5ee3e31400cf"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'classification': 'BAD',\n"," 'event_type': 'accident',\n"," 'severity': 'high',\n"," 'deaths': 1,\n"," 'injured': None,\n"," 'main_incident_location': 'Karur',\n"," 'other_locations': 'Erode, Tiruppur, Kodumudi, Coimbatore',\n"," 'summary': \"A violent clash broke out between farmers and textile groups in Karur district, resulting in one protester's death.\",\n"," 'location_details': {'district': 'Karur',\n","  'state': 'TAMIL NADU',\n","  'district_code': 613,\n","  'state_code': 33}}"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["text = \"Heavy rains that started in Chikkamagaluru triggered flooding downstream in Shivamogga district, but the worst damage was reported in Davanagere where two houses collapsed early Monday morning. Although no deaths were reported, four people suffered serious injuries. Teams from Bengaluru were deployed to assist, while authorities in Hassan remained on alert for possible landslides.\"\n","\n","result = extract_full_incident(text)\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XbUZuHKuI76q","executionInfo":{"status":"ok","timestamp":1763640106153,"user_tz":-330,"elapsed":418,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"02d8b718-e4ef-42fc-f181-6368835b7010"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'classification': 'BAD',\n"," 'event_type': 'natural disaster',\n"," 'severity': 'high',\n"," 'deaths': 0,\n"," 'injured': 4,\n"," 'main_incident_location': 'Davanagere',\n"," 'other_locations': ['Chikkamagaluru', 'Shivamogga', 'Bengaluru', 'Hassan'],\n"," 'summary': 'Heavy rains triggered flooding and house collapses in Davanagere, with no reported deaths but four serious injuries.',\n"," 'location_details': {'district': 'Davanagere',\n","  'state': 'KARNATAKA',\n","  'district_code': 567,\n","  'state_code': 29}}"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["text = \"A businessman from Hyderabad travelling to Visakhapatnam was allegedly kidnapped near Vijayawada but was later found safe in Guntur after a police chase that extended into Ongole. Early reports mistakenly claimed the abduction happened in Hyderabad, but officials later clarified that the crime occurred near Nandigama toll plaza.\"\n","\n","result = extract_full_incident(text)\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iy8oO4TVI79T","executionInfo":{"status":"ok","timestamp":1763640136580,"user_tz":-330,"elapsed":363,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"3dee435f-b095-467e-d175-2bb6273f08ea"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'classification': 'BAD',\n"," 'event_type': 'crime',\n"," 'severity': 'high',\n"," 'deaths': 0,\n"," 'injured': 0,\n"," 'main_incident_location': 'Nandigama toll plaza',\n"," 'other_locations': ['Visakhapatnam',\n","  'Ongole',\n","  'Vijayawada',\n","  'Guntur',\n","  'Hyderabad'],\n"," 'summary': 'A businessman was kidnapped near Vijayawada but was later found safe in Guntur after a police chase.',\n"," 'location_details': None}"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["text = \"In a significant achievement, students from Kochi won a national robotics competition in New Delhi on the same day a tragic boat accident in Alappuzha claimed the lives of two tourists. Authorities said rescue operations were quick, preventing further casualties.\"\n","\n","result = extract_full_incident(text)\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"On7S1rpQJRJv","executionInfo":{"status":"ok","timestamp":1763640186902,"user_tz":-330,"elapsed":396,"user":{"displayName":"20MSC21 HAVISHYANAND T","userId":"14439371810918651563"}},"outputId":"05df7fd5-5b65-4ab6-e3d1-aa6495787586"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'classification': 'GOOD',\n"," 'event_type': 'achievement',\n"," 'severity': 'low',\n"," 'deaths': 2,\n"," 'injured': 0,\n"," 'main_incident_location': 'Alappuzha',\n"," 'other_locations': ['Kochi', 'New Delhi'],\n"," 'summary': 'Students from Kochi won a national robotics competition in New Delhi, while a tragic boat accident in Alappuzha claimed two lives.',\n"," 'location_details': {'district': 'Alappuzha',\n","  'state': 'KERALA',\n","  'district_code': 598,\n","  'state_code': 32}}"]},"metadata":{},"execution_count":56}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}